{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbbb110-ef8e-43b9-9afd-25db7c4db47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de3842-1545-4c0c-813f-b29542d0d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pde.models.fuxi_v2 import FuxiV2VRWKV\n",
    "from pde.train_utils.train_v3 import train\n",
    "from pde.train_utils.dataloader_openstl import load_data\n",
    "from pde.train_utils.losses import calculate_pde_and_continuity_loss, weighted_mae_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52771ce-667b-48f7-829e-8b9f9e52f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/home/fa.buzaev/data_5/\"\n",
    "last_hour_in = 13\n",
    "last_hour_out = 85\n",
    "exp_root = 'exp3_default_params_vrwkv'\n",
    "model_root = f\"/home/asutkin/kursach/{exp_root}/best_models/model_with_fno.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c61272-6158-4caf-875a-8b33c3b51c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train, dataloader_vali, dataloader_test, mean, std = load_data(batch_size=12,\n",
    "                                                                          val_batch_size=12,\n",
    "                                                                          data_root=data_root,\n",
    "                                                                          num_workers=6,\n",
    "                                                                          # data_split='2_8125',\n",
    "                                                                          # data_name='mv3',\n",
    "                                                                          data_split='5_625',\n",
    "                                                                          data_name='uv10',\n",
    "                                                                          # data_name='mv6',\n",
    "                                                                          # train_time=['1979', '2015'],\n",
    "                                                                          train_time=['2010', '2011'],\n",
    "                                                                          val_time=['2016', '2016'],\n",
    "                                                                          test_time=['2017', '2018'],\n",
    "                                                                          idx_in=[*range(1, last_hour_in)],\n",
    "                                                                          idx_out=[*range(last_hour_in, last_hour_out)],\n",
    "                                                                          step=1,\n",
    "                                                                          level=1,\n",
    "                                                                          distributed=False, use_augment=False, \n",
    "                                                                          use_prefetcher=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8304b0-4b7d-46ba-a2d6-f8ed6c054f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "model = FuxiV2VRWKV(img_size=(2, 32, 64), patch_size=(2, 4, 4), in_chans=12, out_chans=2, embed_dim=192, num_groups=16, num_heads=8, window_size=7, depth=12).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "best_loss=float('inf')\n",
    "with open(f\"/home/asutkin/kursach/{exp_root}/logs.txt\", 'a') as file:\n",
    "    for i in range(5):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for x_train, y_train in tqdm(dataloader_train, desc='Training'):\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            big_loss = 0\n",
    "            for j in range(1, last_hour_out - last_hour_in):\n",
    "                time_tensor = j * torch.ones(x_train.shape[0], device=x_train.device).unsqueeze(-1)\n",
    "                prediction = model(x_train, time_tensor)\n",
    "                loss = criterion(prediction, y_train[:,j,:,:,:])\n",
    "                x_train = torch.cat((x_train[:,1:,:,:,:], prediction.unsqueeze(1)), dim=1)\n",
    "                big_loss += loss\n",
    "            big_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += big_loss.item() / (last_hour_out - last_hour_in)\n",
    "            # torch.cuda.empty_cache()\n",
    "        train_loss /= len(dataloader_train)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        for x_val, y_val in tqdm(dataloader_vali, desc='Validating'):\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            big_loss_val = 0\n",
    "            for j in range(1, last_hour_out - last_hour_in):\n",
    "                time_tensor = j * torch.ones(x_val.shape[0], device=x_val.device).unsqueeze(-1)\n",
    "                prediction = model(x_val, time_tensor)\n",
    "                loss = criterion(prediction, y_val[:,j,:,:,:])\n",
    "                x_val = torch.cat((x_val[:,1:,:,:,:], prediction.unsqueeze(1)), dim=1)\n",
    "                big_loss_val += loss\n",
    "            val_loss += big_loss_val.item() / (last_hour_out - last_hour_in)\n",
    "        val_loss /= len(dataloader_vali)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save({\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }, model_root)\n",
    "\n",
    "        print(f\"Epoch: {i + 1}; Train_loss: {train_loss}; Vall_loss: {val_loss}\")\n",
    "        log = json.dumps({'Epoch': i+1, 'Train_loss': train_loss, 'Val_loss': val_loss})\n",
    "        file.write(f\"{log}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939b79c-a3c8-4574-afb3-58c6a17f9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = FuxiV2VRWKV(img_size=(2, 32, 64), patch_size=(2, 4, 4), in_chans=12, out_chans=2, embed_dim=192, num_groups=16, num_heads=8, window_size=7, depth=12).to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "checkpoint = torch.load(model_root)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "running_loss = 0\n",
    "for x_test, y_test in tqdm(dataloader_vali):\n",
    "    x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "    big_loss = 0\n",
    "    for i in range(1, (last_hour_out - last_hour_in)):\n",
    "        time_tensor = i * torch.ones(x_test.shape[0], device=x_test.device).unsqueeze(-1)\n",
    "        prediction = model(x_test, time_tensor)\n",
    "        loss = criterion(prediction, y_test[:,i,:,:,:])\n",
    "        torch.cat((x_test[:,1:,:,:,:], prediction.unsqueeze(1)), dim=1)\n",
    "        big_loss += loss\n",
    "    running_loss += big_loss.item() / (last_hour_out - last_hour_in)\n",
    "running_loss / len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0e4f5-70d4-460a-8e59-61ac25a2b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "def denorm(item, std, mean, idx=0):\n",
    "    mean = mean.squeeze()[idx]\n",
    "    std = std.squeeze()[idx]\n",
    "    item_denorm = item * std + mean\n",
    "    return item_denorm\n",
    "\n",
    "for x_test, y_test in dataloader_test:\n",
    "    x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "    break\n",
    "    \n",
    "x_test_ = torch.empty(x_test.shape, device=device)\n",
    "\n",
    "model.eval()\n",
    "t = 0\n",
    "x_data = x_test\n",
    "\n",
    "for i in range(1, 73):\n",
    "    time_tensor = i * torch.ones(x_test.shape[0], device=x_test.device).unsqueeze(-1)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(x_data, time_tensor)\n",
    "    plt.figure(constrained_layout=True, figsize=(32, 6))\n",
    "    x_data = torch.cat((x_data[:,1:,:,:,:], prediction.unsqueeze(1)), dim=1)\n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.imshow(denorm(prediction[7, 0], std, mean).squeeze().detach().cpu().numpy())\n",
    "    plt.title(f\"Prediction U wind by Andrew, step={t}\")\n",
    "    # plt.colorbar()\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(denorm(y_test[7, t, 0], std, mean).squeeze().detach().cpu().numpy())\n",
    "    plt.title(f\"True answer, step={t}\")\n",
    "    plt.colorbar(boundaries=np.linspace(-20, 20, 20)) \n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(np.abs(denorm(prediction[7, 0], std, mean).squeeze().detach().cpu().numpy() - denorm(y_test[7, t, 0], std, mean).squeeze().detach().cpu().numpy()))\n",
    "    plt.title(f\"Absolute difference, step={t}\")\n",
    "    plt.colorbar(boundaries=np.linspace(0, 20, 20))\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    plt.savefig(f\"/home/asutkin/kursach/{exp_root}/predictions/imvp_{t}.png\")\n",
    "\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1f995-286d-4a02-ab79-e2c81fb52b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "images = []\n",
    "for i in range(0,72):\n",
    "    images.append(imageio.imread(f\"/home/asutkin/kursach/{exp_root}/predictions/imvp_{i}.png\"))\n",
    "\n",
    "\n",
    "imageio.mimsave(f\"/home/asutkin/kursach/{exp_root}/predictions/wind_FNO.gif\", images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-vrwkv]",
   "language": "python",
   "name": "conda-env-.conda-vrwkv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
